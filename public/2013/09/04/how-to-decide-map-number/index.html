<!DOCTYPE html>













<html class="theme-next mist" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






  
  
    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/Han/3.3.0/han.min.css">
















  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  
    
      
    

    
  

  
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






  

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.2',
    sidebar: {"position":"left","display":"remove","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？">
<meta name="keywords" content="hive,mapreduce">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive中如何确定map数">
<meta property="og:url" content="http://javachen.github.io/2013/09/04/how-to-decide-map-number/index.html">
<meta property="og:site_name" content="JavaChen Blog">
<meta property="og:description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg">
<meta property="og:image" content="http://javachen.github.io/images/implement-of-hiveinputformat.png">
<meta property="og:updated_time" content="2019-06-29T12:24:11.021Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive中如何确定map数">
<meta name="twitter:description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？">
<meta name="twitter:image" content="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg">



  <link rel="alternate" href="/atom.xml" title="JavaChen Blog" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://javachen.github.io/2013/09/04/how-to-decide-map-number/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Hive中如何确定map数 | JavaChen Blog</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?50bc6f5d9b045b5895ff44f8bbdbc611";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JavaChen Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">Ramblings of a coder</h1>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://javachen.github.io/2013/09/04/how-to-decide-map-number/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JavaChen">
      <meta itemprop="description" content="Rumblings by a coder on Java、Hadoop and so on">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JavaChen Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">Hive中如何确定map数<a href="https://github.com/javachen/javachen-blog-theme/tree/master/source/_posts/2013/2013-09-04-how-to-decide-map-number.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil"></i></a>

              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2013-09-04 00:00:00" itemprop="dateCreated datePublished" datetime="2013-09-04T00:00:00+08:00">2013-09-04</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-29 20:24:11" itemprop="dateModified" datetime="2019-06-29T20:24:11+08:00">2019-06-29</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/hive/" itemprop="url" rel="index"><span itemprop="name">hive</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <!--/删除
          
              <div class="post-description">
                  Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？
              </div>
          
          -->

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <p>Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？</p>
<p>本文测试集群版本：<code>cdh-4.3.0</code> 。</p>
<h1 id="hive-默认的-input-format"><a href="#hive-默认的-input-format" class="headerlink" title="hive 默认的 input format"></a>hive 默认的 input format</h1><p>在 <code>cdh-4.3.0</code> 的 hive 中查看 <code>hive.input.format</code> 值（为什么是<code>hive.input.format</code>？）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span> hive.input.format;</span><br><span class="line">hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>可以看到默认值为 CombineHiveInputFormat，如果你使用的是 <code>IDH</code> 的hive，则默认值为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span> hive.input.format;</span><br><span class="line">hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>CombineHiveInputFormat 类继承自 HiveInputFormat，而 HiveInputFormat 实现了 <code>org.apache.hadoop.mapred.InputFormat</code> 接口，关于 InputFormat 的分析，可以参考<a href="http://flyingdutchman.iteye.com/blog/1876400" target="_blank" rel="noopener">Hadoop深入学习：InputFormat组件</a>.</p>
<h1 id="InputFormat-接口功能"><a href="#InputFormat-接口功能" class="headerlink" title="InputFormat 接口功能"></a>InputFormat 接口功能</h1><p>简单来说，InputFormat 主要用于描述输入数据的格式，提供了以下两个功能： </p>
<p>1)、数据切分，按照某个策略将输入数据且分成若干个 split，以便确定 Map Task 的个数即 Mapper 的个数，在 MapReduce 框架中，一个 split 就意味着需要一个 Map Task; </p>
<p>2)、为 Mapper 提供输入数据，即给定一个 split(使用其中的 RecordReader 对象)将之解析为一个个的 key/value 键值对。 </p>
<p>该类接口定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">InputFormat</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> InputSplit[] getSplits(JobConf job,<span class="keyword">int</span> numSplits) <span class="keyword">throws</span> IOException; </span><br><span class="line">	<span class="function"><span class="keyword">public</span> RecordReader&lt;K,V&gt; <span class="title">getRecordReader</span><span class="params">(InputSplit split,JobConf job,Reporter reporter)</span> <span class="keyword">throws</span> IOException</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中，<code>getSplit()</code> 方法主要用于切分数据，每一份数据由，split 只是在逻辑上对数据分片，并不会在磁盘上将数据切分成 split 物理分片，实际上数据在 HDFS 上还是以 block 为基本单位来存储数据的。InputSplit 只记录了 Mapper 要处理的数据的元数据信息，如起始位置、长度和所在的节点。</p>
<p>MapReduce 自带了一些 InputFormat 的实现类： </p>
<p><img src="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg" alt="InputFormat实现类"></p>
<p>hive 中有一些 InputFormat 的实现类，如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AvroContainerInputFormat</span><br><span class="line">RCFileBlockMergeInputFormat</span><br><span class="line">RCFileInputFormat</span><br><span class="line">FlatFileInputFormat</span><br><span class="line">OneNullRowInputFormat</span><br><span class="line">ReworkMapredInputFormat</span><br><span class="line">SymbolicInputFormat</span><br><span class="line">SymlinkTextInputFormat</span><br><span class="line">HiveInputFormat</span><br></pre></td></tr></table></figure>

<p>HiveInputFormat 的子类有：</p>
<p><img src="/images/implement-of-hiveinputformat.png" alt="HiveInputFormat的子类"></p>
<h1 id="HiveInputFormat"><a href="#HiveInputFormat" class="headerlink" title="HiveInputFormat"></a>HiveInputFormat</h1><p>以 HiveInputFormat 为例，看看其getSplit()方法逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Path dir : dirs) &#123;</span><br><span class="line">  PartitionDesc part = getPartitionDescFromPath(pathToPartitionInfo, dir);</span><br><span class="line">  <span class="comment">// create a new InputFormat instance if this is the first time to see this</span></span><br><span class="line">  <span class="comment">// class</span></span><br><span class="line">  Class inputFormatClass = part.getInputFileFormatClass();</span><br><span class="line">  InputFormat inputFormat = getInputFormatFromCache(inputFormatClass, job);</span><br><span class="line">  Utilities.copyTableJobPropertiesToConf(part.getTableDesc(), newjob);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Make filter pushdown information available to getSplits.</span></span><br><span class="line">  ArrayList&lt;String&gt; aliases =</span><br><span class="line">      mrwork.getPathToAliases().get(dir.toUri().toString());</span><br><span class="line">  <span class="keyword">if</span> ((aliases != <span class="keyword">null</span>) &amp;&amp; (aliases.size() == <span class="number">1</span>)) &#123;</span><br><span class="line">    Operator op = mrwork.getAliasToWork().get(aliases.get(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">if</span> ((op != <span class="keyword">null</span>) &amp;&amp; (op <span class="keyword">instanceof</span> TableScanOperator)) &#123;</span><br><span class="line">      TableScanOperator tableScan = (TableScanOperator) op;</span><br><span class="line">      pushFilters(newjob, tableScan);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  FileInputFormat.setInputPaths(newjob, dir);</span><br><span class="line">  newjob.setInputFormat(inputFormat.getClass());</span><br><span class="line">  InputSplit[] iss = inputFormat.getSplits(newjob, numSplits / dirs.length);</span><br><span class="line">  <span class="keyword">for</span> (InputSplit is : iss) &#123;</span><br><span class="line">    result.add(<span class="keyword">new</span> HiveInputSplit(is, inputFormatClass.getName()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面代码主要过程是：</p>
<blockquote>
<p>遍历每个输入目录，然后获得 PartitionDesc 对象，从该对象调用 getInputFileFormatClass 方法得到实际的 InputFormat 类，并调用其 <code>getSplits(newjob, numSplits / dirs.length)</code> 方法。</p>
</blockquote>
<p>按照上面代码逻辑，似乎 hive 中每一个表都应该有一个 InputFormat 实现类。在 hive 中运行下面代码，可以查看建表语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show create table info; </span><br><span class="line">OK</span><br><span class="line"><span class="keyword">CREATE</span>  <span class="keyword">TABLE</span> info(</span><br><span class="line">  statist_date <span class="keyword">string</span>, </span><br><span class="line">  statistics_date <span class="keyword">string</span>, </span><br><span class="line">  inner_code <span class="keyword">string</span>, </span><br><span class="line">  office_no <span class="keyword">string</span>, </span><br><span class="line">  window_no <span class="keyword">string</span>, </span><br><span class="line">  ticket_no <span class="keyword">string</span>, </span><br><span class="line">  id_kind <span class="keyword">string</span>, </span><br><span class="line">  id_no <span class="keyword">string</span>, </span><br><span class="line">  id_name <span class="keyword">string</span>, </span><br><span class="line">  area_center_code <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line">  <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\;'</span> </span><br><span class="line">  <span class="keyword">LINES</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\n'</span> </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> INPUTFORMAT </span><br><span class="line">  <span class="string">'org.apache.hadoop.mapred.TextInputFormat'</span> </span><br><span class="line">OUTPUTFORMAT </span><br><span class="line">  <span class="string">'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'</span></span><br><span class="line">LOCATION</span><br><span class="line">  <span class="string">'hdfs://node:8020/user/hive/warehouse/info'</span></span><br><span class="line">TBLPROPERTIES (</span><br><span class="line">  <span class="string">'numPartitions'</span>=<span class="string">'0'</span>, </span><br><span class="line">  <span class="string">'numFiles'</span>=<span class="string">'1'</span>, </span><br><span class="line">  <span class="string">'transient_lastDdlTime'</span>=<span class="string">'1378245263'</span>, </span><br><span class="line">  <span class="string">'numRows'</span>=<span class="string">'0'</span>, </span><br><span class="line">  <span class="string">'totalSize'</span>=<span class="string">'301240320'</span>, </span><br><span class="line">  <span class="string">'rawDataSize'</span>=<span class="string">'0'</span>)</span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.497</span> <span class="keyword">seconds</span></span><br></pre></td></tr></table></figure>

<p>从上面可以看到 info 表的 INPUTFORMAT 为<code>org.apache.hadoop.mapred.TextInputFormat</code>，TextInputFormat 继承自FileInputFormat。FileInputFormat 是一个抽象类，它最重要的功能是为各种 InputFormat 提供统一的 <code>getSplits()</code>方法，该方法最核心的是文件切分算法和 Host 选择算法。</p>
<p>算法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> length = file.getLen();</span><br><span class="line"><span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</span><br><span class="line"><span class="keyword">long</span> minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</span><br><span class="line">FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</span><br><span class="line"></span><br><span class="line"><span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line"><span class="keyword">long</span> splitSize = computeSplitSize(goalSize, minSize, blockSize);</span><br><span class="line"><span class="keyword">long</span> bytesRemaining = length;</span><br><span class="line"><span class="keyword">while</span> (((<span class="keyword">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class="line">String[] splitHosts = getSplitHosts(blkLocations, </span><br><span class="line">	length-bytesRemaining, splitSize, clusterMap);</span><br><span class="line">	splits.add(makeSplit(path, length-bytesRemaining, splitSize, </span><br><span class="line">		       splitHosts));</span><br><span class="line">	bytesRemaining -= splitSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><code>华丽的分割线</code>：以下摘抄自<a href="http://flyingdutchman.iteye.com/blog/1876400" target="_blank" rel="noopener">Hadoop深入学习：InputFormat组件</a></p>
<p><strong>1）文件切分算法</strong> </p>
<p>文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段，FileInputSplit以文件为单位切分生成InputSplit。有三个属性值来确定InputSplit的个数：</p>
<ul>
<li><code>goalSize</code>：该值由 <code>totalSize/numSplits</code> 来确定 InputSplit 的长度，它是根据用户的期望的 InputSplit 个数计算出来的；numSplits 为用户设定的 Map Task 的个数，默认为1。 </li>
<li><code>minSize</code>：由配置参数 <code>mapred.min.split.size</code>（或者 <code>mapreduce.input.fileinputformat.split.minsize</code>）决定的 InputForma t的最小长度，默认为1。 </li>
<li><code>blockSize</code>：HDFS 中的文件存储块block的大小，默认为64MB。</li>
<li><code>numSplits=mapred.map.tasks</code> 或者 <code>mapreduce.job.maps</code> </li>
</ul>
<p>这三个参数决定一个 InputFormat 分片的最终的长度，计算方法如下： </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">splitSize = max&#123;minSize,min&#123;goalSize,blockSize&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>计算出了分片的长度后，也就确定了 InputFormat 的数目。 </p>
<p><strong>2）host 选择算法</strong></p>
<p>InputFormat 的切分方案确定后，接下来就是要确定每一个 InputSplit 的元数据信息。InputSplit 元数据通常包括四部分，<code>&lt;file,start,length,hosts&gt;</code>其意义为： </p>
<ul>
<li>file 标识 InputSplit 分片所在的文件； </li>
<li>InputSplit 分片在文件中的的起始位置； </li>
<li>InputSplit 分片的长度； </li>
<li>分片所在的 host 节点的列表。 </li>
</ul>
<p>InputSplit 的 host 列表的算作策略直接影响到运行作业的本地性。</p>
<p>我们知道，由于大文件存储在 HDFS上的 block 可能会遍布整个 Hadoop 集群，而一个 InputSplit 分片的划分算法可能会导致一个 split 分片对应多个不在同一个节点上的 blocks，这就会使得在 Map Task 执行过程中会涉及到读其他节点上的属于该 Task 的 block 中的数据，从而不能实现数据本地性，而造成更多的网络传输开销。</p>
<p>一个 InputSplit 分片对应的 blocks 可能位于多个数据节点地上，但是基于任务调度的效率，通常情况下，不会把一个分片涉及的所有的节点信息都加到其host列表中，而是选择包含该分片的数据总量的最大的前几个节点，作为任务调度时判断是否具有本地性的主要凭证。</p>
<p>FileInputFormat 使用了一个启发式的 host 选择算法：首先按照 rack 机架包含的数据量对 rack 排序，然后再在 rack 内部按照每个 node 节点包含的数据量对 node 排序，最后选取前 N 个(N 为 block 的副本数)，node 的 host 作为 InputSplit 分片的 host 列表。当任务地调度 Task 作业时，只要将 Task 调度给 host 列表上的节点，就可以认为该 Task 满足了本地性。</p>
<p>从上面的信息我们可以知道，当 InputSplit 分片的大小大于 block 的大小时，Map Task 并不能完全满足数据的本地性，总有一本分的数据要通过网络从远程节点上读数据，故为了提高 Map Task 的数据本地性，减少网络传输的开销，应尽量是 InputFormat 的大小和 HDFS 的 block 块大小相同。</p>
<hr>
<h1 id="CombineHiveInputFormat"><a href="#CombineHiveInputFormat" class="headerlink" title="CombineHiveInputFormat"></a>CombineHiveInputFormat</h1><p><code>getSplits(JobConf job, int numSplits)</code> 代码运行过程如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">init(job);</span><br><span class="line">CombineFileInputFormatShim combine = ShimLoader.getHadoopShims().getCombineFileInputFormat();</span><br><span class="line">	ShimLoader.loadShims(HADOOP_SHIM_CLASSES, HadoopShims.class);</span><br><span class="line">		Hadoop23Shims</span><br><span class="line">			HadoopShimsSecure.getCombineFileInputFormat()</span><br></pre></td></tr></table></figure>

<p>CombineFileInputFormatShim 继承了<code>org.apache.hadoop.mapred.lib.CombineFileInputFormat</code>，CombineFileInputFormatShim 的 <code>getSplits</code> 方法代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> InputSplitShim[] getSplits(JobConf job, <span class="keyword">int</span> numSplits) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">long</span> minSize = job.getLong(<span class="string">"mapred.min.split.size"</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For backward compatibility, let the above parameter be used</span></span><br><span class="line">  <span class="keyword">if</span> (job.getLong(<span class="string">"mapred.min.split.size.per.node"</span>, <span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">super</span>.setMinSplitSizeNode(minSize);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (job.getLong(<span class="string">"mapred.min.split.size.per.rack"</span>, <span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">super</span>.setMinSplitSizeRack(minSize);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (job.getLong(<span class="string">"mapred.max.split.size"</span>, <span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">super</span>.setMaxSplitSize(minSize);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  InputSplit[] splits = (InputSplit[]) <span class="keyword">super</span>.getSplits(job, numSplits);</span><br><span class="line"></span><br><span class="line">  InputSplitShim[] isplits = <span class="keyword">new</span> InputSplitShim[splits.length];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> pos = <span class="number">0</span>; pos &lt; splits.length; pos++) &#123;</span><br><span class="line">    isplits[pos] = <span class="keyword">new</span> InputSplitShim((CombineFileSplit)splits[pos]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> isplits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面代码可以看出，如果为 CombineHiveInputFormat，则以下四个参数起作用：</p>
<ul>
<li><code>mapred.min.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize</code>。</li>
<li><code>mapred.max.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.maxsize</code>。</li>
<li><code>mapred.min.split.size.per.rack</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.rack</code>。</li>
<li><code>mapred.min.split.size.per.node</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.node</code>。</li>
</ul>
<p>CombineFileInputFormatShim 的 getSplits 方法最终会调用父类的 getSplits 方法，拆分算法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> left = locations[i].getLength();</span><br><span class="line"><span class="keyword">long</span> myOffset = locations[i].getOffset();</span><br><span class="line"><span class="keyword">long</span> myLength = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> (maxSize == <span class="number">0</span>) &#123;</span><br><span class="line">		myLength = left;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> (left &gt; maxSize &amp;&amp; left &lt; <span class="number">2</span> * maxSize) &#123;</span><br><span class="line">	  myLength = left / <span class="number">2</span>;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	  myLength = Math.min(maxSize, left);</span><br><span class="line">	&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	OneBlockInfo oneblock = <span class="keyword">new</span> OneBlockInfo(path, myOffset,</span><br><span class="line">	  myLength, locations[i].getHosts(), locations[i]</span><br><span class="line">	      .getTopologyPaths());</span><br><span class="line">	left -= myLength;</span><br><span class="line">	myOffset += myLength;</span><br><span class="line"></span><br><span class="line">	blocksList.add(oneblock);</span><br><span class="line">&#125; <span class="keyword">while</span> (left &gt; <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<h1 id="hive-中如何确定-map-数"><a href="#hive-中如何确定-map-数" class="headerlink" title="hive 中如何确定 map 数"></a>hive 中如何确定 map 数</h1><p>总上总结如下：</p>
<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat</code>，则这时候的参数如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span> mapred.min.split.size;</span><br><span class="line">mapred.min.split.size=1</span><br><span class="line">hive&gt; <span class="built_in">set</span> mapred.map.tasks;</span><br><span class="line">mapred.map.tasks=2</span><br><span class="line">hive&gt; <span class="built_in">set</span> dfs.blocksize;</span><br><span class="line">dfs.blocksize=134217728</span><br></pre></td></tr></table></figure>

<p>上面参数中 <code>mapred.map.tasks</code> 为2，<code>dfs.blocksize</code>（使用的是 cdh-4.3.0 版本的 hadoop，这里 block 和 size 之间没有逗号）为128M。</p>
<p>假设有一个文件为200M，则按上面 <code>HiveInputFormat</code> 的 split 算法：</p>
<p>1、文件总大小为200M，goalSize=200M /2 =100M，minSize=1 ，splitSize = max{1,min{100M,128M}} =100M</p>
<p>2、200M / 100M &gt;1.1,故第一块大小为100M</p>
<p>3、剩下文件大小为100M，小于128M，故第二块大小为100M。</p>
<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</code>，则这时候的参数如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span> mapred.min.split.size;</span><br><span class="line">mapred.min.split.size=1</span><br><span class="line">hive&gt; <span class="built_in">set</span> mapred.max.split.size;</span><br><span class="line">mapred.max.split.size=67108864</span><br><span class="line">hive&gt; <span class="built_in">set</span> mapred.min.split.size.per.rack;</span><br><span class="line">mapred.min.split.size.per.rack=1</span><br><span class="line">hive&gt; <span class="built_in">set</span> mapred.min.split.size.per.node;</span><br><span class="line">mapred.min.split.size.per.node=1</span><br><span class="line">hive&gt; <span class="built_in">set</span> dfs.blocksize;</span><br><span class="line">dfs.blocksize=134217728</span><br></pre></td></tr></table></figure>

<p>上面参数中 <code>mapred.max.split.size</code> 为64M，<code>dfs.blocksize</code> 为128M。</p>
<p>假设有一个文件为200M，则按上面 <code>CombineHiveInputFormat</code> 的 split 算法：</p>
<p>1、128M &lt; 200M &lt;128M X 2，故第一个block大小为128M</p>
<p>2、剩下文件大小为200M-128M=72M，72M &lt; 128M,故第二块大小为72M</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>网上有一些文章关于 hive 中如何控制 map 数的文章是否考虑的不够全面，没有具体情况具体分析。简而言之，当 InputFormat 的实现类为不同类时，拆分块算法都不一样，相关设置参数也不一样，需要具体分析。</p>
<h2 id="1-map-数不是越多越好"><a href="#1-map-数不是越多越好" class="headerlink" title="1. map 数不是越多越好"></a>1. map 数不是越多越好</h2><p>如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个 map 任务来完成，而一个 map 任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。<br>而且，同时可执行的 map 数是受限的。</p>
<h2 id="2-如何适当的增加-map-数？"><a href="#2-如何适当的增加-map-数？" class="headerlink" title="2. 如何适当的增加 map 数？"></a>2. 如何适当的增加 map 数？</h2><ul>
<li>将数据导入到 hive 前，手动将大文件拆分为小文件</li>
<li>指定 map 数，使用 <code>insert</code> 或者 <code>create as select</code> 语句将一个表导入到另一个表，然后对另一张表做查询</li>
</ul>
<h2 id="3-一些经验"><a href="#3-一些经验" class="headerlink" title="3. 一些经验"></a>3. 一些经验</h2><ul>
<li><p>合并小文件可以减少 map 数，但是会增加网络 IO。</p>
</li>
<li><p>尽量使拆分块大小和 hdfs 的块大小接近，避免一个拆分块大小上的多个 hdfs 块位于不同数据节点，从而降低网络 IO。</p>
</li>
<li><p>根据实际情况，控制 map 数量需要遵循两个原则：<code>使大数据量利用合适的map数</code>；<code>使单个map任务处理合适的数据量。</code></p>
</li>
</ul>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><ul>
<li>[1] <a href="http://f.dataguru.cn/thread-149820-1-1.html" target="_blank" rel="noopener">hive的查询注意事项以及优化总结</a></li>
<li>[2] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c010178qd.html" target="_blank" rel="noopener">Hadoop中map数的计算</a></li>
<li>[3] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c0101aqvv.html" target="_blank" rel="noopener">[Hive]从一个经典案例看优化mapred.map.tasks的重要性</a></li>
<li>[4] <a href="http://superlxw1234.iteye.com/blog/1582880" target="_blank" rel="noopener">hive优化之——控制hive任务中的map数和reduce数</a></li>
<li>[5] <a href="http://www.searchtb.com/2010/12/hadoop-job-tuning.html" target="_blank" rel="noopener">Hadoop Job Tuning</a></li>
<li>[6] <a href="http://www.tuicool.com/articles/77f2Af" target="_blank" rel="noopener">Hive配置项的含义详解（2）</a></li>
<li>[7] <a href="http://blog.csdn.net/lalaguozhe/article/details/9053645" target="_blank" rel="noopener">Hive小文件合并调研</a></li>
<li>[8] <a href="http://flyingdutchman.iteye.com/blog/1876400" target="_blank" rel="noopener">Hadoop深入学习：InputFormat组件</a></li>
</ul>

      
    </div>

    

    
    
    


    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>JavaChen</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="http://javachen.github.io/2013/09/04/how-to-decide-map-number/" title="Hive中如何确定map数">Hive中如何确定map数</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    

    
      
    
    
      <div>
        <div id="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="JavaChen 微信支付">
        <p>微信支付</p>
      </div>
    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="JavaChen 支付宝">
        <p>支付宝</p>
      </div>
    

  </div>
</div>

      </div>
    



    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/hive/" rel="tag"><i class="fa fa-tag"></i> hive</a>
          
            <a href="/tags/mapreduce/" rel="tag"><i class="fa fa-tag"></i> mapreduce</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
            
            
              <div>
                
  <div class="bdsharebuttonbox">
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
    <a href="#" class="bds_tieba" data-cmd="tieba" title="分享到百度贴吧"></a>
    <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
    <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a class="bds_count" data-cmd="count"></a>
  </div>
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "2",
        "bdMiniList": false,
        "bdPic": ""
      },
      "share": {
        "bdSize": "16",
        "bdStyle": "0"
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

              </div>
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2013/08/23/publish-proerties-using-zookeeper/" rel="next" title="使用ZooKeeper实现配置同步">
                <i class="fa fa-chevron-left"></i> 使用ZooKeeper实现配置同步
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2013/10/17/run-mapreduce-with-client-user-in-hive-server2/" rel="prev" title="HiveServer2中使用jdbc客户端用户运行mapreduce">
                HiveServer2中使用jdbc客户端用户运行mapreduce <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2009 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JavaChen</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/velocity/1.2.1/velocity.min.js"></script>

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/velocity/1.2.1/velocity.ui.min.js"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.2"></script>




  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  

  

  

  

  

  
<script>
  $('.highlight').not('.gist .highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      const selection = document.getSelection();
      const selected = selection.rangeCount > 0 ? selection.getRangeAt(0) : false;
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
      ta.blur(); // For iOS
      $(this).blur();
      if (selected) {
        selection.removeAllRanges();
        selection.addRange(selected);
      }
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script>


  

  

</body>
</html>
