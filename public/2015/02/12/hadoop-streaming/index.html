<!DOCTYPE html>













<html class="theme-next mist" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






  
  
    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/Han/3.3.0/han.min.css">
















  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  
    
      
    

    
  

  
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






  

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.2',
    sidebar: {"position":"left","display":"remove","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的优势和能力，来处理大数据。">
<meta name="keywords" content="hadoop,mapreduce,streaming">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop Streaming 原理">
<meta property="og:url" content="http://javachen.github.io/2015/02/12/hadoop-streaming/index.html">
<meta property="og:site_name" content="JavaChen Blog">
<meta property="og:description" content="Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的优势和能力，来处理大数据。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-03-26T08:41:24.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop Streaming 原理">
<meta name="twitter:description" content="Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的优势和能力，来处理大数据。">



  <link rel="alternate" href="/atom.xml" title="JavaChen Blog" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://javachen.github.io/2015/02/12/hadoop-streaming/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Hadoop Streaming 原理 | JavaChen Blog</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?50bc6f5d9b045b5895ff44f8bbdbc611";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JavaChen Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">Ramblings of a coder</h1>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://javachen.github.io/2015/02/12/hadoop-streaming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JavaChen">
      <meta itemprop="description" content="Rumblings by a coder on Java、Hadoop and so on">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JavaChen Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">Hadoop Streaming 原理<a href="https://github.com/javachen/javachen-blog-theme/tree/master/source/_posts/2015/2015-02-12-hadoop-streaming.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil"></i></a>

              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2015-02-12 00:00:00" itemprop="dateCreated datePublished" datetime="2015-02-12T00:00:00+08:00">2015-02-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-26 16:41:24" itemprop="dateModified" datetime="2019-03-26T16:41:24+08:00">2019-03-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/hadoop/" itemprop="url" rel="index"><span itemprop="name">hadoop</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <!--/删除
          
              <div class="post-description">
                  Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的优势和能力，来处理大数据。
              </div>
          
          -->

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的优势和能力，来处理大数据。</p>
<p>一个简单的示例，以 shell 脚本为例：</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -<span class="ruby">input myInputDirs \</span></span><br><span class="line"><span class="ruby">    -output myOutputDir \</span></span><br><span class="line"><span class="ruby">    -mapper /bin/cat \</span></span><br><span class="line"><span class="ruby">    -reducer /usr/bin/wc</span></span><br></pre></td></tr></table></figure>

<p>Streaming 方式是 <code>基于 Unix 系统的标准输入输出</code> 来进行 MapReduce Job 的运行，它区别与 Pipes 的地方主要是通信协议，Pipes 使用的是 Socket 通信，是对使用 C++ 语言来实现 MapReduce Job 并通过 Socket 通信来与 Hadopp 平台通信，完成 Job 的执行。</p>
<p>任何支持标准输入输出特性的编程语言都可以使用 Streaming 方式来实现 MapReduce Job，基本原理就是输入从 Unix 系统标准输入，输出使用 Unix 系统的标准输出。</p>
<p>Hadoop 是使用 Java 语言编写的，所以最直接的方式的就是使用 Java 语言来实现 Mapper 和 Reducer，然后配置 MapReduce Job，提交到集群计算环境来完成计算。但是很多开发者可能对 Java 并不熟悉，而是对一些具有脚本特性的语言，如 C++、Shell、Python、 Ruby、PHP、Perl 有实际开发经验，Hadoop Streaming 为这一类开发者提供了使用 Hadoop 集群来进行处理数据的工具，即工具包 hadoop-streaming.jar。</p>
<p>在标准的输入输出中，Key 和 Value 是以 Tab 作为分隔符，并且在 Reducer 的标准输入中，Hadoop 框架保证了输入的数据是经过了按 Key 排序的。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>Hadoop Streaming 使用了 Unix 的标准输入输出作为 Hadoop 和其他编程语言的开发接口，因此在其他的编程语言所写的程序中，只需要将标准输入作为程序的输入，将标准输出作为程序的输出就可以了。</p>
<p>mapper 和 reducer 会从标准输入中读取用户数据，一行一行处理后发送给标准输出。Streaming 工具会创建 MapReduce 作业，发送给各个 tasktracker，同时监控整个作业的执行过程。</p>
<p>如果一个文件（可执行或者脚本）作为 mapper，mapper 初始化时，每一个 mapper 任务会把该文件作为一个单独进程启动，mapper 任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。 同时，mapper 收集可执行文件进程标准输出的内容，并把收到的每一行内容转化成 key/value 对，作为 mapper 的输出。 默认情况下，一行中第一个 tab 之前的部分作为 key，之后的（不包括tab）作为 value。如果没有 tab，整行作为 key 值，value 值为 null。</p>
<p>对于 reducer，类似。</p>
<p>以上是 Map/Reduce 框架和 streaming mapper/reducer 之间的基本通信协议。</p>
<p>用户可以定义 <code>stream.non.zero.exit.is.failure</code> 参数为 true 或者 false 以定义一个以非0状态退出的 streaming 的任务是失败还是成功。默认情况下，以非0状态退出的任务都任务是失败的。</p>
<h1 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h1><p>命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar [genericOptions] [streamingOptions]</span><br></pre></td></tr></table></figure>

<h2 id="streaming-参数"><a href="#streaming-参数" class="headerlink" title="streaming 参数"></a>streaming 参数</h2><p>以 Hadoop 2.6.0 为例，可选的 streaming 参数如下：</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">是否可选</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>-input directoryname or filename</code></td>
<td align="left">Required</td>
<td align="left">mapper的输入路径</td>
</tr>
<tr>
<td align="left"><code>-output directoryname</code></td>
<td align="left">Required</td>
<td align="left">reducer输出路径</td>
</tr>
<tr>
<td align="left"><code>-mapper executable or JavaClassName</code></td>
<td align="left">Required</td>
<td align="left">Mapper可执行程序或 Java 类名</td>
</tr>
<tr>
<td align="left"><code>-reducer executable or JavaClassName</code></td>
<td align="left">Required</td>
<td align="left">Reducer 可执行程序或 Java 类名</td>
</tr>
<tr>
<td align="left"><code>-file filename</code></td>
<td align="left">Optional</td>
<td align="left">mapper, reducer 或 combiner 依赖的文件</td>
</tr>
<tr>
<td align="left"><code>-inputformat JavaClassName</code></td>
<td align="left">Optional</td>
<td align="left">key/value 输入格式，默认为 TextInputFormat</td>
</tr>
<tr>
<td align="left"><code>-outputformat JavaClassName</code></td>
<td align="left">Optional</td>
<td align="left">key/value 输出格式，默认为  TextOutputformat</td>
</tr>
<tr>
<td align="left"><code>-partitioner JavaClassName</code></td>
<td align="left">Optional</td>
<td align="left">Class that determines which reduce a key is sent to</td>
</tr>
<tr>
<td align="left"><code>-combiner streamingCommand or JavaClassName</code></td>
<td align="left">Optional</td>
<td align="left">map 输出结果执行 Combiner 的命令或者类名</td>
</tr>
<tr>
<td align="left"><code>-cmdenv name=value</code></td>
<td align="left">Optional</td>
<td align="left">环境变量</td>
</tr>
<tr>
<td align="left"><code>-inputreader</code></td>
<td align="left">Optional</td>
<td align="left">向后兼容，定义输入的 Reader 类，用于取代输出格式</td>
</tr>
<tr>
<td align="left"><code>-verbose</code></td>
<td align="left">Optional</td>
<td align="left">输出日志</td>
</tr>
<tr>
<td align="left"><code>-lazyOutput</code></td>
<td align="left">Optional</td>
<td align="left">延时输出</td>
</tr>
<tr>
<td align="left"><code>-numReduceTasks</code></td>
<td align="left">Optional</td>
<td align="left">定义 reduce 数量</td>
</tr>
<tr>
<td align="left"><code>-mapdebug</code></td>
<td align="left">Optional</td>
<td align="left">map 任务运行失败时候，执行的脚本</td>
</tr>
<tr>
<td align="left"><code>-reducedebug</code></td>
<td align="left">Optional</td>
<td align="left">reduce 任务运行失败时候，执行的脚本</td>
</tr>
</tbody></table>
<p>定义 Java 类作为 mapper 和 reducer：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -inputformat org.apache.hadoop.mapred.KeyValueTextInputFormat \</span><br><span class="line">    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \</span><br><span class="line">    -reducer /usr/bin/wc</span><br></pre></td></tr></table></figure>

<p>如果 mapper 和 reducer 的可执行文件在集群上不存在，则可以通过  <code>-file</code> 参数将其提交到集群上去：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper myPythonScript.py \</span><br><span class="line">    -reducer /usr/bin/wc \</span><br><span class="line">    -file myPythonScript.py</span><br></pre></td></tr></table></figure>

<p>你也可以将 mapper 和 reducer 的可执行文件用到的文件和配置上传到集群上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper myPythonScript.py \</span><br><span class="line">    -reducer /usr/bin/wc \</span><br><span class="line">    -file myPythonScript.py \</span><br><span class="line">    -file myDictionary.txt</span><br></pre></td></tr></table></figure>

<p>你也可以定义其他参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-inputformat JavaClassName</span><br><span class="line">-outputformat JavaClassName</span><br><span class="line">-partitioner JavaClassName</span><br><span class="line">-combiner streamingCommand or JavaClassName</span><br></pre></td></tr></table></figure>

<p>定义一个环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-cmdenv EXAMPLE_DIR=/home/example/dictionaries/</span><br></pre></td></tr></table></figure>

<h2 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h2><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">是否可选</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>-conf configuration_file</code></td>
<td align="left">Optional</td>
<td align="left">定义应用的配置文件</td>
</tr>
<tr>
<td align="left"><code>-D property=value</code></td>
<td align="left">Optional</td>
<td align="left">定义参数</td>
</tr>
<tr>
<td align="left"><code>-fs host:port or local</code></td>
<td align="left">Optional</td>
<td align="left">定义 namenode 地址</td>
</tr>
<tr>
<td align="left"><code>-files</code></td>
<td align="left">Optional</td>
<td align="left">定义需要拷贝到 Map/Reduce 集群的文件，多个文件以逗号分隔</td>
</tr>
<tr>
<td align="left"><code>-libjars</code></td>
<td align="left">Optional</td>
<td align="left">定义需要引入到 classpath 的 jar 文件，多个文件以逗号分隔</td>
</tr>
<tr>
<td align="left"><code>-archives</code></td>
<td align="left">Optional</td>
<td align="left">定义需要解压到计算节点的压缩文件，多个文件以逗号分隔</td>
</tr>
</tbody></table>
<p>定义参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-D mapred.local.dir=/tmp/<span class="built_in">local</span></span><br><span class="line">-D mapred.system.dir=/tmp/system</span><br><span class="line">-D mapred.temp.dir=/tmp/temp</span><br></pre></td></tr></table></figure>

<p>定义 reduce 个数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D mapreduce.job.reduces=0</span><br></pre></td></tr></table></figure>

<p>你也可以使用 <code>-D stream.reduce.output.field.separator=SEP</code> 和 <code>-D stream.num.reduce.output.fields=NUM</code> 自定义 mapper 输出的分隔符为SEP，并且按 SEP 分隔之后的前 NUM 部分内容作为 key，如果分隔符少于 NUM，则整行作为 key。例如，下面的例子指定分隔符为 <code>....</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -D stream.map.output.field.separator=. \</span><br><span class="line">    -D stream.num.map.output.key.fields=4 \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper /bin/cat \</span><br><span class="line">    -reducer /bin/cat</span><br></pre></td></tr></table></figure>

<p>hadoop 提供配置供用户自主设置分隔符：</p>
<p><code>-D stream.map.output.field.separator</code> ：设置 map 输出中 key 和 value 的分隔符<br><code>-D stream.num.map.output.key.fields</code> ：设置 map 程序分隔符的位置，该位置之前的部分作为 key，之后的部分作为 value<br><code>-D map.output.key.field.separator</code> : 设置 map 输出分区时 key 内部的分割符<br><code>-D mapreduce.partition.keypartitioner.options</code> : 指定分桶时，key 按照分隔符切割后，其中用于分桶 key 所占的列数（配合 <code>-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</code> 使用）<br><code>-D stream.reduce.output.field.separator</code>：设置 reduce 输出中 key 和 value 的分隔符<br><code>-D stream.num.reduce.output.key.fields</code>：设置 reduce 程序分隔符的位置</p>
<p>定义解压文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">$ ls test_jar/</span><br><span class="line">cache.txt  cache2.txt</span><br><span class="line"></span><br><span class="line">$ jar cvf cachedir.jar -C test_jar/ .</span><br><span class="line">added manifest</span><br><span class="line">adding: cache.txt(<span class="keyword">in</span> = 30) (out= 29)(deflated 3%)</span><br><span class="line">adding: cache2.txt(<span class="keyword">in</span> = 37) (out= 35)(deflated 5%)</span><br><span class="line"></span><br><span class="line">$ hdfs dfs -put cachedir.jar samples/cachefile</span><br><span class="line"></span><br><span class="line">$ hdfs dfs -cat /user/root/samples/cachefile/input.txt</span><br><span class="line">cachedir.jar/cache.txt</span><br><span class="line">cachedir.jar/cache2.txt</span><br><span class="line"></span><br><span class="line">$ cat test_jar/cache.txt</span><br><span class="line">This is just the cache string</span><br><span class="line"></span><br><span class="line">$ cat test_jar/cache2.txt</span><br><span class="line">This is just the second cache string</span><br><span class="line"></span><br><span class="line">$ hadoop jar hadoop-streaming.jar \</span><br><span class="line">                  -archives <span class="string">'hdfs://hadoop-nn1.example.com/user/root/samples/cachefile/cachedir.jar'</span> \</span><br><span class="line">                  -D mapreduce.job.maps=1 \</span><br><span class="line">                  -D mapreduce.job.reduces=1 \</span><br><span class="line">                  -D mapreduce.job.name=<span class="string">"Experiment"</span> \</span><br><span class="line">                  -input <span class="string">"/user/root/samples/cachefile/input.txt"</span> \</span><br><span class="line">                  -output <span class="string">"/user/root/samples/cachefile/out"</span> \</span><br><span class="line">                  -mapper <span class="string">"xargs cat"</span> \</span><br><span class="line">                  -reducer <span class="string">"cat"</span></span><br><span class="line"></span><br><span class="line">$ hdfs dfs -ls /user/root/samples/cachefile/out</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup        0 2013-11-14 17:00 /user/root/samples/cachefile/out/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup       69 2013-11-14 17:00 /user/root/samples/cachefile/out/part-00000</span><br><span class="line"></span><br><span class="line">$ hdfs dfs -cat /user/root/samples/cachefile/out/part-00000</span><br><span class="line">This is just the cache string</span><br><span class="line">This is just the second cache string</span><br></pre></td></tr></table></figure>

<h2 id="复杂的例子"><a href="#复杂的例子" class="headerlink" title="复杂的例子"></a>复杂的例子</h2><h3 id="Hadoop-Partitioner-Class"><a href="#Hadoop-Partitioner-Class" class="headerlink" title="Hadoop Partitioner Class"></a>Hadoop Partitioner Class</h3><p>Hadoop 中有一个类 <a href="http://hadoop.apache.org/docs/r2.6.0/api/org/apache/hadoop/mapred/lib/KeyFieldBasedPartitioner.html" target="_blank" rel="noopener">KeyFieldBasedPartitioner</a>，可以将 map 输出的内容按照分隔后的一定列，而不是整个 key 内容进行分区，例如：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -D stream.map.output.field.separator=. \</span><br><span class="line">    -D stream.num.map.output.key.fields=4 \</span><br><span class="line">    -D map.output.key.field.separator=. \</span><br><span class="line">    -D mapreduce.partition.keypartitioner.options=-k1,2 \</span><br><span class="line">    -D mapreduce.job.reduces=12 \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper /bin/cat \</span><br><span class="line">    -reducer /bin/cat \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</span><br></pre></td></tr></table></figure>

<p>关键参数说明：</p>
<ul>
<li><code>map.output.key.field.separator=.</code>：设置 map 输出分区时 key 内部的分割符为 <code>.</code></li>
<li><code>mapreduce.partition.keypartitioner.options=-k1,2</code>：设置按前两个字段分区</li>
<li><code>mapreduce.job.reduces=12</code>：reduce 数为12</li>
</ul>
<p>假设 map 的输出为：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.2</span></span><br><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.3</span></span><br><span class="line">11<span class="selector-class">.11</span><span class="selector-class">.4</span><span class="selector-class">.1</span></span><br><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.1</span></span><br><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.2</span></span><br></pre></td></tr></table></figure>

<p>按照前两个字段进行分区，则会分为三个分区：</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">11.11.4.1</span><br><span class="line">-----------</span><br><span class="line">11.12.1.2</span><br><span class="line">11.12.1.1</span><br><span class="line">-----------</span><br><span class="line">11.14.2.3</span><br><span class="line">11.14.2.2</span><br></pre></td></tr></table></figure>

<p>在每个分区内对整行内容排序后为：</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">11.11.4.1</span><br><span class="line">-----------</span><br><span class="line">11.12.1.1</span><br><span class="line">11.12.1.2</span><br><span class="line">-----------</span><br><span class="line">11.14.2.2</span><br><span class="line">11.14.2.3</span><br></pre></td></tr></table></figure>

<h3 id="Hadoop-Comparator-Class"><a href="#Hadoop-Comparator-Class" class="headerlink" title="Hadoop Comparator Class"></a>Hadoop Comparator Class</h3><p>Hadoop 中有一个类 <a href="http://hadoop.apache.org/docs/r2.6.0/api/org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.html" target="_blank" rel="noopener">KeyFieldBasedComparator</a>，提供了 Unix/GNU 中排序的一部分特性。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \</span><br><span class="line">    -D stream.map.output.field.separator=. \</span><br><span class="line">    -D stream.num.map.output.key.fields=4 \</span><br><span class="line">    -D mapreduce.map.output.key.field.separator=. \</span><br><span class="line">    -D mapreduce.partition.keycomparator.options=-k2,2nr \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper /bin/cat \</span><br><span class="line">    -reducer /bin/cat</span><br></pre></td></tr></table></figure>

<p>关键参数说明：</p>
<ul>
<li><code>mapreduce.partition.keycomparator.options=-k2,2nr</code>：指定第二个字段为排序字段，<code>-n</code> 是指按自然顺序排序，<code>-r</code> 指倒叙排序。</li>
</ul>
<p>假设 map 的输出为：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.2</span></span><br><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.3</span></span><br><span class="line">11<span class="selector-class">.11</span><span class="selector-class">.4</span><span class="selector-class">.1</span></span><br><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.1</span></span><br><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.2</span></span><br></pre></td></tr></table></figure>

<p>则 reduce 输出结果为：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.3</span></span><br><span class="line">11<span class="selector-class">.14</span><span class="selector-class">.2</span><span class="selector-class">.2</span></span><br><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.2</span></span><br><span class="line">11<span class="selector-class">.12</span><span class="selector-class">.1</span><span class="selector-class">.1</span></span><br><span class="line">11<span class="selector-class">.11</span><span class="selector-class">.4</span><span class="selector-class">.1</span></span><br></pre></td></tr></table></figure>

<h3 id="Hadoop-Aggregate-Package"><a href="#Hadoop-Aggregate-Package" class="headerlink" title="Hadoop Aggregate Package"></a>Hadoop Aggregate Package</h3><p>Hadoop 中有一个类 <a href="http://hadoop.apache.org/docs/r2.6.0/org/apache/hadoop/mapred/lib/aggregate/package-summary.html" target="_blank" rel="noopener">Aggregate</a>，Aggregate 提供了一个特定的 reduce 类和 combiner 类，以及一些对 reduce 输出的聚合函数，例如 sum、min、max 等等。</p>
<p>为了使用 Aggregate，只需要定义 <code>-reducer aggregate</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper myAggregatorForKeyCount.py \</span><br><span class="line">    -reducer aggregate \</span><br><span class="line">    -file myAggregatorForKeyCount.py \</span><br></pre></td></tr></table></figure>

<p>myAggregatorForKeyCount.py  文件大概内容如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateLongCountToken</span><span class="params">(id)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"LongValueSum:"</span> + id + <span class="string">"\t"</span> + <span class="string">"1"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv)</span>:</span></span><br><span class="line">    line = sys.stdin.readline();</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            line = line[:<span class="number">-1</span>];</span><br><span class="line">            fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">print</span> generateLongCountToken(fields[<span class="number">0</span>]);</span><br><span class="line">            line = sys.stdin.readline();</span><br><span class="line">    <span class="keyword">except</span> <span class="string">"end of file"</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">     main(sys.argv)</span><br></pre></td></tr></table></figure>

<h3 id="Hadoop-Field-Selection-Class"><a href="#Hadoop-Field-Selection-Class" class="headerlink" title="Hadoop Field Selection Class"></a>Hadoop Field Selection Class</h3><p>Hadoop 中有一个类 <a href="http://hadoop.apache.org/docs/r2.6.0/api/org/apache/hadoop/mapred/lib/FieldSelectionMapReduce.html" target="_blank" rel="noopener">FieldSelectionMapReduce</a>，运行你像 unix 中的 cut 命令一样处理文本。</p>
<p>例子：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming.jar \</span><br><span class="line">    -D mapreduce.map.output.key.field.separator=. \</span><br><span class="line">    -D mapreduce.partition.keypartitioner.options=-k1,2 \</span><br><span class="line">    -D mapreduce.fieldsel.data.field.separator=. \</span><br><span class="line">    -D mapreduce.fieldsel.map.output.key.value.fields.spec=6,5,1-3:0- \</span><br><span class="line">    -D mapreduce.fieldsel.reduce.output.key.value.fields.spec=0-2:5- \</span><br><span class="line">    -D mapreduce.map.output.key.class=org.apache.hadoop.io.Text \</span><br><span class="line">    -D mapreduce.job.reduces=12 \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper org.apache.hadoop.mapred.lib.FieldSelectionMapReduce \</span><br><span class="line">    -reducer org.apache.hadoop.mapred.lib.FieldSelectionMapReduce \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</span><br></pre></td></tr></table></figure>

<p>关键参数说明：</p>
<ul>
<li><code>mapreduce.fieldsel.map.output.key.value.fields.spec=6,5,1-3:0-</code>：意思是 map 的输出中 key 部分包括分隔后的第 6、5、1、2、3列，而 value 部分包括分隔后的所有的列</li>
<li><code>mapreduce.fieldsel.reduce.output.key.value.fields.spec=0-2:5-</code>：意思是 map 的输出中 key 部分包括分隔后的第 0、1、2列，而 value 部分包括分隔后的从第5列开始的所有列</li>
</ul>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>上面讲了 Hadoop Streaming 的原理和一些用法，现在来运行一些例子做测试。关于如何用 Python 来编写 Hadoop Streaming 程序，可以参考 <a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank" rel="noopener">Writing an Hadoop MapReduce Program in Python</a>，中文翻译在 <a href="http://www.tianjun.ml/essays/19/" target="_blank" rel="noopener">这里</a>，其他非 Java 的语言，都可以参照这篇文章。</p>
<p>下面以 word count 为例做测试。</p>
<h2 id="准备测试数据"><a href="#准备测试数据" class="headerlink" title="准备测试数据"></a>准备测试数据</h2><p>同 <a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank" rel="noopener">Writing an Hadoop MapReduce Program in Python</a>，我们使用古腾堡项目中的三本电子书作为测试：</p>
<ul>
<li><a href="http://www.gutenberg.org/etext/20417" target="_blank" rel="noopener">The Outline of Science, Vol. 1 (of 4) by J. Arthur Thomson</a></li>
<li><a href="http://www.gutenberg.org/etext/5000" target="_blank" rel="noopener">The Notebooks of Leonardo Da Vinci</a></li>
<li><a href="http://www.gutenberg.org/etext/4300" target="_blank" rel="noopener">Ulysses by James Joyce</a></li>
</ul>
<p>下载这些电子书的 txt格式，并将其上传到 hdfs：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /tmp/gutenberg/ &amp;&amp; <span class="built_in">cd</span> /tmp/gutenberg/</span><br><span class="line"></span><br><span class="line">$ wget http://www.gutenberg.org/files/20417/20417.txt</span><br><span class="line">$ wget http://www.gutenberg.org/cache/epub/5000/pg5000.txt</span><br><span class="line">$ wget http://www.gutenberg.org/files/4300/4300.txt</span><br><span class="line"></span><br><span class="line">$ hadoop fs -copyFromLocal /tmp/gutenberg gutenberg</span><br><span class="line"></span><br><span class="line">$ hadoop fs -ls gutenberg</span><br><span class="line">Found 4 items</span><br><span class="line">-rw-r--r--   3 hive hive     674762 2015-02-11 17:34 gutenberg/20417.txt</span><br><span class="line">-rw-r--r--   3 hive hive    1573079 2015-02-11 17:34 gutenberg/4300.txt</span><br><span class="line">-rw-r--r--   3 hive hive    1423803 2015-02-11 17:34 gutenberg/pg5000.txt</span><br></pre></td></tr></table></figure>

<h2 id="编写-Shell-版程序"><a href="#编写-Shell-版程序" class="headerlink" title="编写 Shell 版程序"></a>编写 Shell 版程序</h2><p>mapper.sh 如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> LINE; <span class="keyword">do</span></span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> <span class="variable">$LINE</span></span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$word</span> 1"</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>reducer.sh 程序如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line">count=0</span><br><span class="line">started=0</span><br><span class="line">word=<span class="string">""</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> LINE;<span class="keyword">do</span></span><br><span class="line">  newword=`<span class="built_in">echo</span> <span class="variable">$LINE</span> | cut -d <span class="string">' '</span>  -f 1`</span><br><span class="line">  <span class="keyword">if</span> [ <span class="string">"<span class="variable">$word</span>"</span> != <span class="string">"<span class="variable">$newword</span>"</span> ];<span class="keyword">then</span></span><br><span class="line">    [ <span class="variable">$started</span> -ne 0 ] &amp;&amp; <span class="built_in">echo</span> -e <span class="string">"<span class="variable">$word</span>\t<span class="variable">$count</span>"</span></span><br><span class="line">    word=<span class="variable">$newword</span></span><br><span class="line">    count=1</span><br><span class="line">    started=1</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    count=$(( <span class="variable">$count</span> + 1 ))</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"<span class="variable">$word</span>\t<span class="variable">$count</span>"</span></span><br></pre></td></tr></table></figure>

<p>在本机以脚本方式测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">"foo foo quux labs foo bar quux"</span> | sh mapper.sh  |sort -k1,1| sh reducer.sh</span><br><span class="line">bar 1</span><br><span class="line">foo 3</span><br><span class="line">labs    1</span><br><span class="line">quux    2</span><br></pre></td></tr></table></figure>

<p>以 Hadoop Streaming 方式运行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop  jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \</span><br><span class="line">    -D mapred.reduce.tasks=6 \</span><br><span class="line">    -input gutenberg/* \</span><br><span class="line">    -output gutenberg-output \</span><br><span class="line">    -mapper mapper.sh\</span><br><span class="line">    -reducer reducer.sh\</span><br><span class="line">    -file mapper.sh \</span><br><span class="line">    -file reducer.sh</span><br><span class="line"></span><br><span class="line">15/02/11 17:50:59 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">15/02/11 17:51:18 INFO mapreduce.Job:  map 17% reduce 0%</span><br><span class="line">15/02/11 17:51:52 INFO mapreduce.Job:  map 17% reduce 6%</span><br><span class="line">15/02/11 17:51:53 INFO mapreduce.Job:  map 33% reduce 6%</span><br><span class="line">15/02/11 17:51:55 INFO mapreduce.Job:  map 60% reduce 17%</span><br><span class="line">15/02/11 17:51:56 INFO mapreduce.Job:  map 100% reduce 17%</span><br><span class="line">15/02/11 17:51:59 INFO mapreduce.Job:  map 100% reduce 67%</span><br><span class="line">15/02/11 17:53:11 INFO mapreduce.Job:  map 100% reduce 68%</span><br><span class="line">15/02/11 17:54:49 INFO mapreduce.Job:  map 100% reduce 69%</span><br><span class="line">15/02/11 17:57:12 INFO mapreduce.Job:  map 100% reduce 70%</span><br><span class="line">15/02/11 17:58:45 INFO mapreduce.Job:  map 100% reduce 71%</span><br><span class="line">15/02/11 17:58:55 INFO mapreduce.Job:  map 100% reduce 81%</span><br><span class="line">15/02/11 17:59:05 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">15/02/11 17:59:08 INFO streaming.StreamJob: Job complete: job_1421752803837_5736</span><br><span class="line">15/02/11 17:59:09 INFO streaming.StreamJob: Output: /user/root/gutenberg-output</span><br></pre></td></tr></table></figure>

<h2 id="编写-Python-版程序"><a href="#编写-Python-版程序" class="headerlink" title="编写 Python 版程序"></a>编写 Python 版程序</h2><p>mapper.py 程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""A more advanced Mapper, using Python iterators and generators."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_input</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">        <span class="comment"># split the line into words</span></span><br><span class="line">        <span class="keyword">yield</span> line.split()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="comment"># input comes from STDIN (standard input)</span></span><br><span class="line">    data = read_input(sys.stdin)</span><br><span class="line">    <span class="keyword">for</span> words <span class="keyword">in</span> data:</span><br><span class="line">        <span class="comment"># write the results to STDOUT (standard output);</span></span><br><span class="line">        <span class="comment"># what we output here will be the input for the</span></span><br><span class="line">        <span class="comment"># Reduce step, i.e. the input for reducer.py</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># tab-delimited; the trivial word count is 1</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'%s%s%d'</span> % (word, separator, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>reducer.py 程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""A more advanced Reducer, using Python iterators and generators."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> groupby</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_mapper_output</span><span class="params">(file, separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">        <span class="keyword">yield</span> line.rstrip().split(separator, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="comment"># input comes from STDIN (standard input)</span></span><br><span class="line">    data = read_mapper_output(sys.stdin, separator=separator)</span><br><span class="line">    <span class="comment"># groupby groups multiple word-count pairs by word,</span></span><br><span class="line">    <span class="comment"># and creates an iterator that returns consecutive keys and their group:</span></span><br><span class="line">    <span class="comment">#   current_word - string containing a word (the key)</span></span><br><span class="line">    <span class="comment">#   group - iterator yielding all ["&amp;lt;current_word&amp;gt;", "&amp;lt;count&amp;gt;"] items</span></span><br><span class="line">    <span class="keyword">for</span> current_word, group <span class="keyword">in</span> groupby(data, itemgetter(<span class="number">0</span>)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            total_count = sum(int(count) <span class="keyword">for</span> current_word, count <span class="keyword">in</span> group)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"%s%s%d"</span> % (current_word, separator, total_count)</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="comment"># count was not a number, so silently discard this item</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>关于 Java 的一些例子，这个需要单独创建一个 maven 工程，然后做一些测试。</p>
<h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><h3 id="mapper-中不能使用-shell-的别名，但可以使用变量"><a href="#mapper-中不能使用-shell-的别名，但可以使用变量" class="headerlink" title="mapper 中不能使用 shell 的别名，但可以使用变量"></a>mapper 中不能使用 shell 的别名，但可以使用变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -cat /user/me/samples/student_marks</span><br><span class="line">alice   50</span><br><span class="line">bruce   70</span><br><span class="line">charlie 80</span><br><span class="line">dan     75</span><br><span class="line"></span><br><span class="line">$ c2=<span class="string">'cut -f2'</span>; hadoop jar hadoop-streaming-2.6.0.jar \</span><br><span class="line">    -D mapreduce.job.name=<span class="string">'Experiment'</span> \</span><br><span class="line">    -input /user/me/samples/student_marks \</span><br><span class="line">    -output /user/me/samples/student_out \</span><br><span class="line">    -mapper <span class="string">"<span class="variable">$c2</span>"</span> -reducer <span class="string">'cat'</span></span><br><span class="line"></span><br><span class="line">$ hdfs dfs -cat /user/me/samples/student_out/part-00000</span><br><span class="line">50</span><br><span class="line">70</span><br><span class="line">75</span><br><span class="line">80</span><br></pre></td></tr></table></figure>

<h3 id="mapper-中不能使用-unix-的管道"><a href="#mapper-中不能使用-unix-的管道" class="headerlink" title="mapper 中不能使用 unix 的管道"></a>mapper 中不能使用 unix 的管道</h3><p><code>-mapper</code> 中使用 “cut -f1 | sed s/foo/bar/g”，会出现 <code>java.io.IOException: Broken pipe</code> 异常</p>
<h3 id="指定-streaming-临时空间"><a href="#指定-streaming-临时空间" class="headerlink" title="指定 streaming 临时空间"></a>指定 streaming 临时空间</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D stream.tmpdir=/<span class="built_in">export</span>/bigspace/...</span><br></pre></td></tr></table></figure>

<h3 id="指定多个输入文件"><a href="#指定多个输入文件" class="headerlink" title="指定多个输入文件"></a>指定多个输入文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming-2.6.0.jar \</span><br><span class="line">    -input <span class="string">'/user/foo/dir1'</span> -input <span class="string">'/user/foo/dir2'</span> \</span><br><span class="line">    (rest of the <span class="built_in">command</span>)</span><br></pre></td></tr></table></figure>

<h3 id="处理-XML"><a href="#处理-XML" class="headerlink" title="处理 XML"></a>处理 XML</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-streaming-2.6.0.jar \</span><br><span class="line">    -inputreader <span class="string">"StreamXmlRecord,begin=BEGIN_STRING,end=END_STRING"</span> \</span><br><span class="line">    (rest of the <span class="built_in">command</span>)</span><br></pre></td></tr></table></figure>

<p>BEGIN_STRING 和 END_STRING 之前的内容会被认为是 map 任务的一条记录。</p>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><ul>
<li><a href="http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/HadoopStreaming.html#More_Usage_Examples" target="_blank" rel="noopener">Hadoop Streaming</a></li>
<li><a href="http://dongxicheng.org/mapreduce/hadoop-streaming-programming/" target="_blank" rel="noopener">Hadoop Streaming 编程</a></li>
<li><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank" rel="noopener">Writing an Hadoop MapReduce Program in Python</a></li>
</ul>

      
    </div>

    

    
    
    


    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>JavaChen</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="http://javachen.github.io/2015/02/12/hadoop-streaming/" title="Hadoop Streaming 原理">Hadoop Streaming 原理</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    

    
      
    
    
      <div>
        <div id="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="JavaChen 微信支付">
        <p>微信支付</p>
      </div>
    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="JavaChen 支付宝">
        <p>支付宝</p>
      </div>
    

  </div>
</div>

      </div>
    



    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"><i class="fa fa-tag"></i> hadoop</a>
          
            <a href="/tags/mapreduce/" rel="tag"><i class="fa fa-tag"></i> mapreduce</a>
          
            <a href="/tags/streaming/" rel="tag"><i class="fa fa-tag"></i> streaming</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
            
            
              <div>
                
  <div class="bdsharebuttonbox">
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
    <a href="#" class="bds_tieba" data-cmd="tieba" title="分享到百度贴吧"></a>
    <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
    <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a class="bds_count" data-cmd="count"></a>
  </div>
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "2",
        "bdMiniList": false,
        "bdPic": ""
      },
      "share": {
        "bdSize": "16",
        "bdStyle": "0"
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

              </div>
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/02/10/reading-list-2015-02/" rel="next" title="Reading List 2015-02">
                <i class="fa fa-chevron-left"></i> Reading List 2015-02
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/02/28/install-and-config-hue/" rel="prev" title="安装和配置Hue">
                安装和配置Hue <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2009 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JavaChen</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/velocity/1.2.1/velocity.min.js"></script>

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/velocity/1.2.1/velocity.ui.min.js"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.2"></script>




  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  

  

  

  

  

  
<script>
  $('.highlight').not('.gist .highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      const selection = document.getSelection();
      const selected = selection.rangeCount > 0 ? selection.getRangeAt(0) : false;
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
      ta.blur(); // For iOS
      $(this).blur();
      if (selected) {
        selection.removeAllRanges();
        selection.addRange(selected);
      }
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script>


  

  

</body>
</html>
