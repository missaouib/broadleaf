---
layout: post
title: Nginx服务器
category: devops
tags: nginx
description: 本文主要是参考相关资料，整理了Nginx服务器的安装、配置和使用示例。
---


# 1、常用Web服务器介绍

apache、Nginx、tomcat、weblogic、iis、jboss、websphere、jetty、netty、lighttpd、glassfish、resin

## Apache

Apache仍然是时长占用量最高的web服务器，据最新数据统计，市场占有率目前是50%左右。主要优势在于一个是比较早出现的一个Http静态资源服务器，同时又是开源的。所以在技术上的支持以及市面上的各种解决方案都比较成熟。Apache支持的模块非常丰富。

## Lighttpd

Lighttpd其设计目标是提供一个专门针对高性能网站、安全、快速、兼容性好并且灵活的web server环境。特点是：内存开销低、CPU占用率低、性能好、模块丰富。Lighttpd跟Nginx一样，是一款轻量级的Web服务器。跟Nginx的定位类似

## Tomcat

Tomcat大家都比较熟悉，是一个开源的JSP Servlet容器。

## **Nginx**

Nginx是俄罗斯人编写的一款高性能的HTTP和反向代理服务器，在高连接并发的情况下，它能够支持高达50000个并发连接数的响应，但是内存、CPU等系统资源消耗却很低，运行很稳定。目前Nginx在国内很多大型企业都有应用，据最新统计，Nginx的市场占有率已经到33%左右了。而Apache的市场占有率虽然仍然是最高的，但是是呈下降趋势。而Nginx的势头很明显。选择Nginx的理由也很简单：第一，它可以支持5W高并发连接；第二，内存消耗少；第三，成本低，如果采用F5、NetScaler等硬件负载均衡设备的话，需要大几十万。而Nginx是开源的，可以免费使用并且能用于商业用途

**Nginx服务器、Apache Http Server、Tomcat之间的关系**

HTTP服务器本质上也是一种应用程序——它通常运行在服务器之上，绑定服务器的IP地址并监听某一个tcp端口来接收并处理HTTP请求，这样客户端（一般来说是IE, Firefox，Chrome这样的浏览器）就能够通过HTTP协议来获取服务器上的网页（HTML格式）、文档（PDF格式）、音频（MP4格式）、视频（MOV格式）等等资源

![pastedGraphic.png](/images/nginx-0.png)

Apache Tomcat是Apache基金会下的一款开源项目，Tomcat能够动态的生成资源并返回到客户端。

Apache HTTP server 和Nginx都能够将某一个文本文件的内容通过HTTP协议返回到客户端，但是这些文本文件的内容是固定的，也就是说什么情况下访问该文本的内容都是完全一样的，这样的资源我们称之为静态资源。动态资源则相反，不同时间、不同客户端所得到的内容是不同的 ； （虽然apache和nginx本身不支持动态页面，但是他们可以集成模块来支持，比如PHP、Python）

如果想要使用java程序来动态生成资源内容，使用apache server和nginx这一类的http服务器是基本做不到。而Java Servlet技术以及衍生出来的（jsp）Java Server Pages技术可以让Java程序也具有处理HTTP请求并且返回内容的能力，而Apache Tomcat正是支持运行Servlet/JSP应用程序的容器

Tomcat运行在JVM之上，它和HTTP服务器一样，绑定IP地址并监听TCP端口，同时还包含以下职责：

- 管理Servlet程序的生命周期
- 将URL映射到指定的Servlet进行处理
- 与Servlet程序合作处理HTTP请求——根据HTTP请求生成HttpServletResponse对象并传递给Servlet进行处理，将Servlet中的HttpServletResponse对象生成的内容返回给浏览器

虽然Tomcat也可以认为是HTTP服务器，但通常它仍然会和Nginx配合在一起使用：

- 动静态资源分离——运用Nginx的反向代理功能分发请求：所有动态资源的请求交给Tomcat，而静态资源的请求（例如图片、视频、CSS、JavaScript文件等）则直接由Nginx返回到浏览器，这样能大大减轻Tomcat的压力。
- 负载均衡，当业务压力增大时，可能一个Tomcat的实例不足以处理，那么这时可以启动多个Tomcat实例进行水平扩展，而Nginx的负载均衡功能可以把请求通过算法分发到各个不同的实例进行处理

**Apache HTTP Server和Nginx的关系**

Apache Http Server是使用比较广泛也是资格最老的web服务器，是Apache基金会下第一个开源的WEB服务器。在Nginx出现之前，大部分企业使用的都是Apache。

在互联网发展初期，流量不是特别大的时候，使用Apache完全满足需求。但是随着互联网的飞速发展，网站的流量以指数及增长，这个时候除了提升硬件性能以外，Apache Http server也开始遇到瓶颈了，于是这个时候Nginx的出现，就是为了解决大型网站高并发设计的，所以对于高并发来说，Nginx有先天的优势。因此Nginx也在慢慢取代Apache Http server。 而Nginx另一个强大的功能就是反向代理，现在大型网站分工详细，哪些服务器处理数据流，哪些处理静态文件，这些谁指挥，一般都是用nginx反向代理到内网服务器，这样就起到了负载均衡分流的作用。再次nginx高度模块化的设计，编写模块相对简单。

# 2、什么是Nginx

nginx可以作为web服务器，但更多的时候，我们把它作为网关，因为它具备网关必备的功能：

- 反向代理。正向代理的对象是客户端，反向代理代理的是服务端。
- 负载均衡。
- 动态路由。动静分离。
- 请求过滤。

### nginx作为web服务器

Web服务器分2类：

- web应用服务器，如：
  - tomcat
  - resin
  - jetty
- web服务器，如：
  - Apache 服务器
  - Nginx
  - IIS

区分：web服务器不能解析jsp等页面，只能处理js、css、html等静态资源。
并发：web服务器的并发能力远高于web应用服务器。

### nginx作为反向代理

什么是反向代理？

- 代理：通过客户机的配置，实现让一台服务器(代理服务器)代理客户机，客户的所有请求都交给代理服务器处理。
- 反向代理：用一台服务器，代理真实服务器，用户访问时，不再是访问真实服务器，而是代理服务器。

nginx可以当做反向代理服务器来使用：

- 我们需要提前在nginx中配置好反向代理的规则，不同的请求，交给不同的真实服务器处理
- 当请求到达nginx，nginx会根据已经定义的规则进行请求的转发，从而实现路由功能

# 3、安装

## 3.1、mac上安装:

使用brew安装：

```
brew install nginx
```

查看版本：

```
nginx -v
nginx version: nginx/1.17.0
```

安装目录在：/usr/local/Cellar/nginx/1.17.0/

配置文件在：/usr/local/etc/nginx/nginx.conf 

启动和停止：

```
nginx

nginx -s stop
```

指定配置文件启动：

```
nginx -c /mic/data/program/nginx/conf/nginx.conf 
```

如果不指定，默认为`NGINX_HOME/conf/nginx.conf`

测试配置文件是否正确：

```
nginx -t
```

重新加载配置：

```
nginx -s reload
```

刷新dns缓存：

```
sudo dscacheutil -flushcache
```

# 4、配置

nginx的核心配置文件，主要包括三个段：Main、 Event 、 Http

/usr/local/etc/nginx/目录下的配置文件：

```
ll /usr/local/etc/nginx/
total 168
-rw-r--r--  1 june  admin   1.0K  5  8  2015 fastcgi.conf
-rw-r--r--  1 june  admin   1.1K  6 17 18:55 fastcgi.conf.default
-rw-r--r--  1 june  admin   1.1K  6 17 18:55 fastcgi.conf.default.default
-rw-r--r--  1 june  admin   964B  5  8  2015 fastcgi_params
-rw-r--r--  1 june  admin   1.0K  6 17 18:55 fastcgi_params.default
-rw-r--r--  1 june  admin   2.8K  6 17 18:55 koi-utf
-rw-r--r--  1 june  admin   2.2K  6 17 18:55 koi-win
-rw-r--r--  1 june  admin   3.9K  5  8  2015 mime.types
-rw-r--r--  1 june  admin   5.1K  6 17 18:55 mime.types.default
-rw-r--r--  1 june  admin   5.1K  6 17 18:55 mime.types.default.default
-rw-r--r--  1 june  admin   2.0K  6 26 14:44 nginx.conf
-rw-r--r--  1 june  admin   2.6K  6 17 18:55 nginx.conf.default
-rw-r--r--  1 june  admin   2.6K  6 17 18:55 nginx.conf.default.default
-rw-r--r--  1 june  admin   596B  5  8  2015 scgi_params
-rw-r--r--  1 june  admin   636B  6 17 18:55 scgi_params.default
drwxr-xr-x  2 june  admin    64B  6 17 18:55 servers
-rw-r--r--  1 june  admin   623B  5  8  2015 uwsgi_params
-rw-r--r--  1 june  admin   664B  6 17 18:55 uwsgi_params.default
-rw-r--r--  1 june  admin   664B  6 17 18:55 uwsgi_params.default.default
-rw-r--r--  1 june  admin   3.5K  6 17 18:55 win-utf
```

可以查看默认的配置文件`cat nginx.conf.default`：

```json
#user  nobody;
worker_processes  1;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    server {
        listen       8080;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        #
        #location ~ /\.ht {  #/
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}
    include servers/*; 
}
```

## **配置文件的整体结构**

![img](http://t11.baidu.com/it/u=4051409674,36802062&fm=173&app=25&f=JPEG?w=640&h=785&s=F1D75D9AE39745CA58CDB2570300B0FD)

从图中可以看出主要包含以下几大部分内容：

**1. 全局块**

该部分配置主要影响Nginx全局，通常包括下面几个部分：

- 配置运行Nginx服务器用户（组）

- worker process数

- Nginx进程PID

- 存放路径错误日志的存放路径

- 配置文件的引入

**2. events块**

该部分配置主要影响Nginx服务器与用户的网络连接，主要包括：

- 设置网络连接的序列化
- 是否允许同时接收多个网络连接
- 事件驱动模型的选择
- 最大连接数的配置

**3. http块**

- 定义MIMI-Type

- 自定义服务日志

- 允许sendfile方式传输文件

- 连接超时时间

- 单连接请求数上限

**4. server块**

- 配置网络监听
- 基于名称的虚拟主机配置
- 基于IP的虚拟主机配置

**5. location块**

- location配置
- 请求根目录配置
- 更改location的URI
- 网站默认首页配置

![img](http://t11.baidu.com/it/u=1990165744,222287524&fm=173&app=25&f=JPEG?w=640&h=827&s=CE40E11343FFE1CE00F5A5DA0200C0B2)

## 配置示例

一个更完整的nginx.conf示例：

```json
user       www www;  #定义Nginx运行的用户和用户组，默认是nobody
## nginx进程数，建议设置为等于CPU总核心数。Default: 1。设置auto：Nginx进程将自动检测。
worker_processes  5;  
error_log  logs/error.log info;  #全局错误日志定义类型，[debug|info|notice|warn|error|crit]
#file：指定存放路径和文件名称。如果不指定默认置于路径 logs/nginx.pid
pid        logs/nginx.pid; 
#一个nginx进程打开的最多文件描述符数目，建议与ulimit -n的值保持一致。
worker_rlimit_nofile 65535; 

events {
  # 参考事件模型，use [kqueue|rtsig|epoll|/dev/poll|select|poll]; 
    use epoll;
    #单个进程最大连接数（最大连接数=连接数*进程数）
  worker_connections  4096;  ## Default: 1024
}

#设定http服务器
http {
  #该指令主要用于将其他的Nginx配置或者第三方模块的配置引用到当前的主配置文件中
  include    conf/mime.types; #文件扩展名与文件类型映射表
  include    /etc/nginx/proxy.conf;
  include    /etc/nginx/fastcgi.conf;
  index    index.html index.htm index.php; #用户访问web网站时的全局首页

  default_type application/octet-stream; #默认文件类型
  log_format   main '$remote_addr - $remote_user [$time_local]  $status '
    '"$request" $body_bytes_sent "$http_referer" '
    '"$http_user_agent" "$http_x_forwarded_for"';
  access_log   logs/access.log  main;
  
  #是否调用sendfile函数来输出文件，对于普通应用设为 on
  #如果用来进行下载等应用磁盘IO重负载应用，可设置为off
  sendfile     on; 
  tcp_nopush   on; #防止网络阻塞
  tcp_nodelay  on; #防止网络阻塞
  server_names_hash_bucket_size 128; #服务器名字的hash表大小
  
  #长连接超时时间，单位是秒
  keepalive_timeout  65;
  
  gzip on; # 采用gzip压缩的形式发送数据
  
  #为指定的客户端禁用gzip功能。我们设置成IE6或者更低版本以使我们的方案能够广泛兼容
  gzip_disable "msie6"; 
  
  #和http头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过gzip压缩的页面
  # gzip_vary on; 
  
  #设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。
  #默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。
  # gzip_min_length 1k;
  
  #允许或者禁止压缩基于请求和响应的响应流。设置为any，意味着将会压缩所有的请求。
  # gzip_proxied any; 
  
  #设置数据的压缩等级，可以是1-9之间的任意数值，9是最慢但是压缩比最大的。
  # gzip_comp_level 6; 
  
  #设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。
  #4 16k代表以16k为单位，安装原始数据大小以16k为单位的4倍申请内存。
  # gzip_buffers 16 8k; 
  
  #用于识别 http 协议的版本
  # gzip_http_version 1.1; 
  
  # gzip_types text/plain text/css application/json application/javascript
  text/xml application/xml application/xml+rss text/javascript;

  #虚拟主机的配置
  server { # php/fastcgi
    listen       80; #监听端口
    server_name  domain1.com www.domain1.com; #域名可以有多个，用空格隔开
    access_log   logs/domain1.access.log  main; #用于指定该虚拟主机服务器中的访问记录日志存放路径
    root         html; #表示整个server虚拟主机内的根目录，所有当前主机中web项目的根目录

    location ~ \.php$ {
      fastcgi_pass   127.0.0.1:1025;
    }
  }

  #简单的反向代理设置，动静分离
  server { 
    listen       80;  #监听端口，默认80，小于1024的要以root启动。
    server_name  domain2.com www.domain2.com;
    access_log   logs/domain2.access.log  main;
    charset        utf-8; #用于设置网页的默认编码格式


    # 静态文件，设置过期时间
    location ~ ^/(images|javascript|js|css|flash|media|static)/  {
      root    /var/www/virtual/big.server.com/htdocs; #本地路径
      expires 30d;
    }

    # 反向代理的服务端ip和端口
    location / {  #对 “/” 启用反向代理
      #请求转向backend定义的服务器列表，即反向代理，对应upstream负载均衡器。也可以proxy_pass http://ip:port。          
      proxy_pass      http://127.0.0.1:8080; 
      proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_fo
      proxy_set_header Host $host;          
    }
  }

  #upstream模块主要负责负载均衡的配置，通过默认的轮询调度方式来分发请求到后端服务器
  upstream big_server_com {
    #ip_hash;  #指定请求调度算法，可选：ip_hash、least_conn，默认是weight权重轮询调度
    server 192.168.0.1:7998 weight=5;
    server 192.168.0.1:7999 backup; #预留的备份服务器
    server 192.168.0.1:8000 down; #表示该主机暂停服务
    server 192.168.0.1:8001 max_fails=3; #表示失败最大次数，超过失败最大次数暂停服务
    server 192.168.0.1:8002 fail_timeout=20s;#表示如果请求受理失败，暂停指定的时间之后重新发起请求

  }

  #简单的负载均衡设置
  server { 
    listen          80;
    server_name     big.server.com;
    access_log      logs/big.server.access.log main;

    location / {
      proxy_pass      http://big_server_com;
    }
  }
}
```

一个proxy.conf示例：

```json
proxy_redirect          off;
proxy_set_header        Host            $host;
proxy_set_header        X-Real-IP       $remote_addr;
proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
client_max_body_size    10m;
client_body_buffer_size 128k;
proxy_connect_timeout   90;
proxy_send_timeout      90;
proxy_read_timeout      90;
proxy_buffers           32 4k;
```

一个fastcgi.conf示例：

```json
fastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;
fastcgi_param  QUERY_STRING       $query_string;
fastcgi_param  REQUEST_METHOD     $request_method;
fastcgi_param  CONTENT_TYPE       $content_type;
fastcgi_param  CONTENT_LENGTH     $content_length;
fastcgi_param  SCRIPT_NAME        $fastcgi_script_name;
fastcgi_param  REQUEST_URI        $request_uri;
fastcgi_param  DOCUMENT_URI       $document_uri;
fastcgi_param  DOCUMENT_ROOT      $document_root;
fastcgi_param  SERVER_PROTOCOL    $server_protocol;
fastcgi_param  GATEWAY_INTERFACE  CGI/1.1;
fastcgi_param  SERVER_SOFTWARE    nginx/$nginx_version;
fastcgi_param  REMOTE_ADDR        $remote_addr;
fastcgi_param  REMOTE_PORT        $remote_port;
fastcgi_param  SERVER_ADDR        $server_addr;
fastcgi_param  SERVER_PORT        $server_port;
fastcgi_param  SERVER_NAME        $server_name;

fastcgi_index  index.php;

fastcgi_param  REDIRECT_STATUS    200;
```

## 配置说明

### master和worker进程

nginx在启动后，会有一个master进程和多个worker进程。master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。nginx的进程模型

## location配置详细解释

语法规则： `location [=|~|~*|^~] /uri/ { … }`

- `=` 开头表示精确匹配
- `^~` 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为`/static/20%/aa`，可以被规则`^~ /static/ /aa`匹配到（注意是空格）。
- `~` 开头表示区分大小写的正则匹配
- `~*` 开头表示不区分大小写的正则匹配
- `!~`和`!~*`分别为区分大小写不匹配及不区分大小写不匹配 的正则
- `/` 通用匹配，任何请求都会匹配到。

![image-20190629133658372](/images/nginx-1.png)

## **负载均衡配置**

upstream是Nginx的HTTP Upstream模块，这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。

Nginx的负载均衡模块目前支持4种调度算法，下面进行分别介绍，其中后两项属于第三方的调度方法。

- `轮询`（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响；
- `Weight`：指定轮询权值，Weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下；
- `least-connected`：最少连接数。将下一个请求分配到连接数最少的那台服务器上
- `ip_hash`：每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题；
- `fair`：比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的`upstream_fair`模块；
- `url_hash`：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的`hash`软件包。

在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有：

- `down`：表示当前的server暂时不参与负载均衡；
- `backup`：预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻；
- `max_fails`：允许请求失败的次数，默认为1。当超过最大次数时，返回`proxy_next_upstream` 模块定义的错误；
- `fail_timeou`t：在经历了max_fails次失败后，暂停服务的时间。`max_fails`可以和`fail_timeout`一起使用。

注意，当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup

## 日志管理

nginx里默认会有两种日志， access.log 访问日志和 error.log错误日志。

##### 访问日志

| $remote_addr          | 客户端的ip地址(代理服务器，显示代理服务ip)           |
| --------------------- | ---------------------------------------------------- |
| $remote_user          | 用于记录远程客户端的用户名称（一般为“-”）            |
| $time_local           | 用于记录访问时间和时区                               |
| $request              | 用于记录请求的url以及请求方法                        |
| $status               | 响应状态码，例如：200成功、404页面找不到等。         |
| $body_bytes_sent      | 给客户端发送的文件主体内容字节数                     |
| $http_user_agent      | 用户所使用的代理（一般为浏览器）                     |
| $http_x_forwarded_for | 可以记录客户端IP，通过代理服务器来记录客户端的ip地址 |
| $http_referer         | 可以记录用户是从哪个链接访问过来的                   |

开启日志：

```json
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
'$status $body_bytes_sent "$http_referer" '
'"$http_user_agent" "$http_x_forwarded_for"';

access_log  logs/access.log  main;
```



# 5、实验

## 5.1、静态资源代理

在nginx上配置一个静态服务，可以实现动态分离，把静态文件放置到nginx机器上，然后location中指定到该路径。

```json
#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile      on;

    keepalive_timeout  65;

    gzip  on;
    server {
          listen       80;
          server_name  static.cshop.com;

          location ~* \.(js|css|png|jpg|jpeg|gif|ico)$ {
             expires max;
             log_not_found off;
          }

                    location ^~ /resource/ {
            alias /usr/local/Cellar/nginx/1.17.0/html/resource/;
            index index.html index.htm;
            expires 1y;
            add_header Cache-Control public;
            add_header Last-Modified "";
            add_header ETag "";
          }
     }
}
```

修改配置文件之后，重新加载配置文件：

```
sudo nginx -s reload
```

上面使用了 static.cshop.com ，需要先在hosts文件中配置一个映射：

```
127.0.0.1 static.cshop.com
127.0.0.1 www.cshop.com
127.0.0.1 api.cshop.com
```

在浏览器服务 http://static.cshop.com/resource/index.html  实际上访问的是/usr/local/Cellar/nginx/1.17.0/html/resource/目录下的index.html文件。

配置说明：

- `^~`指的是匹配以`/resource/`开头的url
- alias是指定路径，路径最后面需要添加上`/`

alias目录和root目录是有区别的：

- alias指定的目录是准确的，即location匹配访问的path目录下的文件直接是在alias目录下查找的；
- root指定的目录是location匹配访问的path目录的上一级目录，这个path目录一定要是真实存在root指定目录下的；
- 使用alias标签的目录块中不能使用rewrite的break；另外，alias指定的目录后面必须要加上"/"符号！！
- alias虚拟目录配置中，location匹配的path目录如果后面不带"/"，那么访问的url地址中这个path目录后面加不加"/"不影响访问，访问时它会自动加上"/"；但是如果location匹配的path目录后面加上"/"，那么访问的url地址中这个path目录必须要加上"/"，访问时它不会自动加上"/"。如果不加上"/"，访问就会失败！
- root目录配置中，location匹配的path目录后面带不带"/"，都不会影响访问。

## 5.2、配置反向代理

配置一个反向代理，当访问 www.cshop.com 时，将请求代理到 http://127.0.0.1:9002 。

```json
#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;

    keepalive_timeout  65;

    gzip  on;
  
    server {
          listen       80;
          server_name  static.cshop.com;

          location ~* \.(js|css|png|jpg|jpeg|gif|ico)$ {
             expires max;
             log_not_found off;
          }

                    location ^~ /resource/ {
            alias /usr/local/Cellar/nginx/1.17.0/html/resource/;
            index index.html index.htm;
            expires 1y;
            add_header Cache-Control public;
            add_header Last-Modified "";
            add_header ETag "";
          }
     }

    server {
          listen       80;
          server_name  www.cshop.com;

          location / {
            proxy_pass http://127.0.0.1:9002;
            #获得真实的用户IP
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            proxy_http_version 1.1; #代理服务的http协议版本，默认设置为1.0版本
            proxy_set_header Connection "";

            proxy_connect_timeout 600;
            proxy_read_timeout 600;
          }
     }
}
```

### 关于X-Forwarded-For

```json
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
```

配置上面三项之后，web服务端就可以可以通过`request.getHeader("X-Forwarded-For")`来获得真实的用户ip。

> X-Forwarded-For：简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP 代理或者负载均衡服务器时才会添加该项。用于识别通过HTTP代理或负载平衡器原始IP一个连接到Web服务器的客户机地址的非rfc标准。

当Nginx有进行`X-Forwarded-For`设置的话，每次经过proxy转发都会有记录，格式就是`client1, proxy1,proxy2`，以逗号隔开各个地址，而且由于他是非rfc标准，所以默认是没有的，需要强制添加，通过Proxy转达的时候，后端服务器看到的远程ip是Proxy的ip，也就是说如果直接使用request.getHeader("X-Forwarded-For")是获取不到用户ip的，那我们要如何设置获得用户ip呢？

此时就需要在nginx配置的location块中添加

```
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for
```

注意这里的意思是增加到`X-Forwarded-For`中，不是覆盖，而增加后的格式就是之前说的`client1,proxy1....”，默认的时候`X-Forwarded-For`是空的，如果有两个nginx，并且都配置了上面这个命令，则会在web服务器的`request.getHeader("X-Forwarded-For")`获得的是`用户ip，第一个nginx的ip`，分别对应之前的格式。

> `proxy_add_forwarded_fo`r包含着两个格式，前面一部分是请求头的`X-Forwarded-For`，而后面`$remote_addr`，也就是说是远程用户的ip

我们来个图浅显的解释下：

![](http://p3.pstatp.com/large/pgc-image/15364111135101c3eeea28c)

**X-real-ip与X-Forwarded-For的区别**

- `X-real-ip`是覆盖，而`X-Forwarded-For`是后面添加
- 举个例子，请求由1.1.1.1发出，经过三层代理，第一层是2.2.2.2，第二层是3.3.3.3，而本次请求的来源IP4.4.4.4是第三层代理，
- 而`X-Real-IP`，没有相关标准，上面的例子，如果配置了`X-Read-IP`，可能会有两种情况
  - 最后一跳是正向代理，可能会保留真实客户端IP，X-Real-IP：1.1.1.1
  - 最后一跳是反向代理，比如Nginx，一般会是与之直接连接的客户端IP，X-Real-IP：3.3.3.3

- 而`X-Forwarded-For`的结果则是

```
X-Forwarded-For：1.1.1.1, 2.2.2.2, 3.3.3.3
```

- 所以如果只有一层代理，则两个值是一样的

关于X-Forwarded-For与X-Real-IP的一些相关文章可以查看：[HTTP 请求头中的 X-Forwarded-For](https://www.runoob.com/w3cnote/http-x-forwarded-for.html) 。

### 关于proxy_http_version

nginx在反向代理HTTP协议的时候，默认使用的是HTTP1.0去向后端服务器获取响应的内容后在返回给客户端。
HTTP1.0和HTTP1.1的一个不同之处就是，**HTTP1.0不支持HTTP keep-alive**，**也就是不支持长连接**。nginx在后端服务器请求时使用了HTTP1.0同时使用HTTP Header的`Connection：Close`通知后端服务器主动关闭连接。这样会导致任何一个客户端的请求都在后端服务器上产生了一个`TIME-WAIT`状态的连接。所以我们需要在Nginx上启用HTTP1.1的向后端发送请求，同时支持Keep-alive。

```json
proxy_http_version 1.1;           # 后端配置支持HTTP1.1，必须配置。
proxy_set_header Connection "";   # 后端配置支持HTTP1.1，必须配置。
```

## 5.3、配置负载均衡

```json
#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;

    keepalive_timeout  65;

    gzip  on;
    server {
          listen       80;
          server_name  static.cshop.com;

          location ~* \.(js|css|png|jpg|jpeg|gif|ico)$ {
             expires max;
             log_not_found off;
          }

          location ^~ /resource/ {
            alias /usr/local/Cellar/nginx/1.17.0/html/resource/;
            index index.html index.htm;
            expires 1y;
            add_header Cache-Control public;
            add_header Last-Modified "";
            add_header ETag "";
          }
     }

    server {
          listen       80;
          server_name  www.cshop.com;

          location / {
            proxy_pass http://127.0.0.1:9002;
            #获得真实的用户IP
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            proxy_http_version 1.1; #代理服务的http协议版本，默认设置为1.0版本
            proxy_set_header Connection "";

            proxy_connect_timeout 600;
            proxy_read_timeout 600;
          }
     }

     upstream  backServer{
            server 192.168.56.100:8080;
            server 192.168.56.100:8081;
       }
     server {
        listen       80;
        server_name  api.chsop.com;
        location / {
           proxy_pass http://backServer;
           index  index.html index.htm;
        }      
     }
}
```

## 5.4、nginx proxy cache缓存

- nginx反向代理前置

- 依靠文件系统缓存索引级的文件

- 依赖内存缓存文件地址

配置：

```json
#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
   
    keepalive_timeout  65;

    gzip  on;
    # 声明一个cahce缓存节点内容
    proxy_cache_path /usr/local/Cellar/nginx/1.17.0/tmp_cache levels=1:2 keys_zone=tmp_cache:100m inactive=7d max_size=10g
    
    server {
          listen       80;
          server_name  www.cshop.com;
          
          location / {
            proxy_pass http://127.0.0.1:9002;
            
            # 声明一个cahce缓存节点内容
            proxy_cache tmp_cache;
            proxy_cache_key $url;
            proxy_cache_valid 200 206 302 304 7d;
            
            proxy_set_header X-Forwarded-Host $host;
            proxy_set_header X-Forwarded-Server $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            proxy_connect_timeout 600;
            proxy_read_timeout 600;
          }
     }
   
}
```

> 这种方式需要依赖本地文件读写，性能不高，故不推荐使用。

## 5.5、静态资源CDN化

参考[变态的静态资源缓存与更新（超详细好文）](https://blog.csdn.net/zhangjs712/article/details/51166748)。

静态资源CDN的过程：

1、DNS用CNAME解析到源站

2、回源缓存设置

3、强推失效

### cache-control响应头

Cache-Control 头用于指定缓存指令，所有请求/响应链的缓存机制必须遵守这个指令。该指令规定行为，意在防止缓存受到请求或响应的不利干扰。通常，这些指令可以覆盖默认的缓存算法。缓存指令是单向的，也就是说，在一个请求中存在缓存指令不意味着也在其响应中存在。

> 注意：HTTP/1.0 缓存没有实现 Cache-Control，只实现了 Pragma: no-cache。

 Cache-Control 响应指令允许源服务器覆盖一个响应默认的缓存功能:

- private：客户端可以缓存
- public：客户端和代理服务器都可以缓存
- max-age=XXX：缓存的内容将在XXX秒后失效
- no-cache：强制想服务端再验证一次
- no-store：缓存请求的任何返回内容

判断顺序：

```
no-store -> no-cache -> public 或者  private ->max-age
```

### 有效性判断



- ETag：资源唯一标识
- If-None-Match：客户端发送的匹配Etag标识符
- Last-modified：资源最后被修改的时间
- If-Modified-Since：客户端发送的匹配资源最后修改的时间的标识符

参考[Expires、Last-Modified、Etag缓存控制](https://www.cnblogs.com/zhouwenhong/p/3928645.html)

### 浏览器第一次请求过程

![img](https://images0.cnblogs.com/blog/648334/images08/221537307378944.jpg)

### 浏览器第二次请求过程

![img](https://images0.cnblogs.com/blog/648334/images08/221538345655678.jpg)

浏览器刷新三种方式：

- 回车刷新或者a链接：看cache-control对应的max-age是否仍然有效，有效则直接从缓存获取。若cache-control中为no-cache，则进入协商逻辑。
- F5或command+R刷新：去掉cache-control中的max-age或者直接设置为0，然后进入缓存协商
- Ctrl+F5或者command+shift+R刷新：去掉cache-control和协商头，强制刷新。

协商机制：比较Last-modified和ETag到服务器，若协商判断没有变化则403不返回数据，否则200返回数据。



### 静态资源部署策略

- 使用版本号，如a.js?v=0.1，不便利，维护困难
- 使用待摘要版本号，如a.js?v=45edw，存在先部署html还是还先部署资源的覆盖问题
- 使用摘要做文件名部署，如45edw.js，新老版本并存并且可以回滚，资源部署完之后再部署html。
- 对静态资源保持生命周期内不会变，max-age可设置的很长，无视失效更新周期
- html文件设置no-cache或较短的max-age，以便于更新
- html文件仍然设置较长的max-age，依靠动态的获取版本号请求发送到后端，异步下载最新的版本号的html后展示渲染在前端
- 动态请求也可以静态化成json资源推送到cdn上
- 依靠异步请求获取后端节点对应的资源状态做紧急下架处理
- 可以紧急推送cdh内容以使其下架等操作

## 5.6、nginx 解决session一致性

**1、session绑定**

**使用ip_hash实现**：

每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 

```
upstream backserver {
  ip_hash;
  server 192.168.0.14:88;
  server 192.168.0.15:80;
}
```

session绑定使用场景：机器数适中、对稳定性要求不是非常苛刻

优点：实现简单、配置方便、没有额外网络开销

缺点：网络中有机器Down掉时、用户Session会丢失、容易造成单点故障。

这种方式不符合对系统的高可用要求，因为一旦某台服务器宕机，那么该机器上的session也就不复存在了，用户请求切换到其他机器后么有session，无法完成业务处理。

使用 **nginx-sticky-module** 模块来实现。

下载编译之后，配置：

```
upstream 192.168.0.10 {
    sticky;
  	server 192.168.0.14:88;
  	server 192.168.0.15:80;
}
```

sticky支持的参数：**sticky [name=route] [domain=.foo.bar] [path=/] [expires=1h] [hash=index|md5|sha1] [no_fallback];**

```yml
name：可以为任何的string字符,默认是route
domain：哪些域名下可以使用这个cookie
path：哪些路径对启用sticky,例如path/test,那么只有test这个目录才会使用sticky做负载均衡
expires：cookie过期时间，默认浏览器关闭就过期，也就是会话方式。
no_fallbackup：如果设置了这个，cookie对应的服务器宕机了，那么将会返回502（bad gateway 或者 proxy error），建议不启用。
```

**2、session 复制**

可以通过tomcat的server.xml文件进行配置，这样每个tomcat都会同步对应的session，那么此时即使某个tomcat被宕机了，也不影响服务。

session复制是早期的企业级的使用比较多的一种服务器集群session管理机制。

应用服务器开启web容器的session复制功能，在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有的session信息，这样任何一台宕机都不会导致session的数据丢失，服务器使用session时，直接从本地获取。

简介： 将一台机器上的Session数据广播复制到集群中其余机器上

session复制使用场景：机器较少，网络流量较小

优点： 实现简单、配置较少、当网络中有机器Down掉时不影响用户访问

缺点：广播式复制到其余机器有一定廷时，带来一定网络开销。

这种方式在应用集群达到数千台的时候，就会出现瓶颈，每台都需要备份session，出现内存不够用的情况。

**3、session 共享**

使用spring session实现session共享，将session存入redis中。

session服务器使用场景：集群中机器数多、网络环境复杂。

优点：可靠性好

缺点：实现复杂、稳定性依赖于缓存的稳定性、Session信息放入缓存时要有合理的策略写入。

**4、利用cookie记录session**

session记录在客户端，每次请求服务器的时候，将session放在请求中发送给服务器，服务器处理完请求后再将修改后的session响应给客户端，这里的客户端就是cookie。

# 6、参考文章

- [Expires、Last-Modified、Etag缓存控制](https://www.cnblogs.com/zhouwenhong/p/3928645.html)
- [HTTP 请求头中的 X-Forwarded-For](https://www.runoob.com/w3cnote/http-x-forwarded-for.html) 